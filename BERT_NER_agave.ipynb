{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10434,
     "status": "ok",
     "timestamp": 1585290291230,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "hq0DEREam14i",
    "outputId": "1cc6ed48-737c-4ec7-8c62-39b2b1c8684a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 8.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.38.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.18.2)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 54.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 52.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.12.27)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.21.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (0.14.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (1.15.27)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.3.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2019.11.28)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_transformers) (2.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=b00cbebd0f5c63e94ed7fb22e5af15a6d113fb29e1b394ebfbb4538d45b57a87\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, pytorch-transformers\n",
      "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.38 sentencepiece-0.1.85\n",
      "Collecting pytorch_pretrained_bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 9.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.38.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.12.27)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.4.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.15.27)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.5)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_pretrained_bert) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_pretrained_bert) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.27->boto3->pytorch_pretrained_bert) (1.12.0)\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\n"
     ]
    }
   ],
   "source": [
    "## ---------------------- START if you want to use google colab, ---------------------- ##\n",
    "# !pip install pytorch_transformers\n",
    "# !pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31055,
     "status": "ok",
     "timestamp": 1585290319181,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "G9Xuqo_Lnb6x",
    "outputId": "acfd4abe-2a76-4380-eb8b-a9a1295537bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3882,
     "status": "ok",
     "timestamp": 1585290328113,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "RIeUQGWSnoK8",
    "outputId": "f6f23673-a8da-4955-f3be-550960504492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Machine_Learning/CSE576/PJ/clicr/dataset-code\n"
     ]
    }
   ],
   "source": [
    "# cd drive/My\\ Drive/'YOUR DATA_PATH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3255,
     "status": "ok",
     "timestamp": 1585290331673,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "j66Agyk6noUT",
    "outputId": "c1e5bb63-74af-4772-c0a7-57d9b1526e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Machine_Learning/CSE576/PJ/clicr/dataset-code\n"
     ]
    }
   ],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-xxrjrCt8Nl"
   },
   "outputs": [],
   "source": [
    "## ---------------------- END if you want to use google colab, ---------------------- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JyRck8UnFjj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_transformers import BertModel,BertTokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2733,
     "status": "ok",
     "timestamp": 1585290652633,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "CoaXi2Xem14t",
    "outputId": "1ec1615f-9503-4889-98ca-b8f2fc3fbbd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  9 23:54:10 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    58W / 300W |   2164MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     23062      C   /packages/7x/anaconda3/5.3.0/bin/python     2153MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QsugR204m14y"
   },
   "outputs": [],
   "source": [
    "from my_process_json import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1MYX5Jqm143"
   },
   "outputs": [],
   "source": [
    "data_reader = MyDataReader(data_path='/content/drive/My Drive/Machine_Learning/CSE576/PJ/clicr/dataset-code/'+ 'train1.0.json', bs=10000)\n",
    "#data_reader = MyDataReader('/home/akobtan/NLP_Project/Project/clicr_dataset/train1.0.json',bs=10000)\n",
    "\n",
    "#data_reader = MyDataReader(bs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMkEAuFpm146"
   },
   "outputs": [],
   "source": [
    "mydata = data_reader.send_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1585290668951,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "lNVwj9fAm149",
    "outputId": "34d4f3e5-681a-492e-96e7-3ed15a001fc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = data_reader.get_data_size()\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPY_5TmIm15B"
   },
   "outputs": [],
   "source": [
    "paragraphs = [e['p'] for e in mydata].copy()\n",
    "paragraph_tags = [e['p_tags'] for e in mydata].copy()\n",
    "queries = [e['q'] for e in mydata].copy()\n",
    "query_tags = [e['q_tags'] for e in mydata].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZz_-jJ7m15G"
   },
   "outputs": [],
   "source": [
    "#creating embeddings for a batch sample from CLICR NOOOOOOO\n",
    "tags_vals = ['B-ans','I-ans','O','[PAD]','[SEP]','[CLS]']\n",
    "tag2idx = {t: i for i, t in enumerate(tags_vals)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1585290675600,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "l3OInENUm15K",
    "outputId": "f5b66e0e-3a06-4350-e281-6ac653f4a53c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyNtpN9Tm15O"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1014,
     "status": "ok",
     "timestamp": 1585290678529,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "aovUCJbvm15R",
    "outputId": "10e75e8d-733e-43ee-f089-86b186679768"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 996,
     "status": "ok",
     "timestamp": 1585290680272,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "UuwY9omJm15Y",
    "outputId": "3f275fde-a82c-4a42-938d-bbf0728206e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-SXM2-16GB'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1970,
     "status": "ok",
     "timestamp": 1585290682959,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "XFM3zvkLm15c",
    "outputId": "271d58db-a3d5-4d9b-bf8c-1352f18d06dd"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXZUfJtSm15q"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "split_size = 200\n",
    "p_tags = copy.deepcopy(paragraph_tags)\n",
    "q_tags = copy.deepcopy(query_tags)\n",
    "tokenized_texts = []\n",
    "labels = []\n",
    "for i,paragraph in enumerate(paragraphs):\n",
    "    texts = []\n",
    "    paragraph_tag = copy.deepcopy(p_tags[i])\n",
    "    #number of splits for current paragraph\n",
    "    n_splits = int(len(paragraph.split())/split_size)\n",
    "    #tokenize split paragraph text appended by full query at the end with <sep> token between paragraph and query\n",
    "    queries[i] = queries[i].replace(\"@placeholder\",\"B\")\n",
    "    texts += [s for s in ['[CLS] ' + ' '.join(paragraph.split()[(split_size*split):(split_size*(split+1))]) + ' [SEP] ' + queries[i] + ' [SEP]' for split in range(n_splits)]]\n",
    "    tokenized_texts += [tokenizer.tokenize(s) for s in ['[CLS] ' + ' '.join(paragraph.split()[(split_size*split):(split_size*(split+1))]) + ' [SEP] ' + queries[i] + ' [SEP]' for split in range(n_splits)]]\n",
    "    #tokenize remainder of splits\n",
    "    if int(len(paragraph.split()) % split_size) > 0:\n",
    "        texts += ['[CLS] ' + ' '.join(paragraph.split()[(n_splits*split_size):]) + ' [SEP] ' + queries[i] + ' [SEP]']\n",
    "        tokenized_texts += [tokenizer.tokenize('[CLS] ' + ' '.join(paragraph.split()[(n_splits*split_size):]) + ' [SEP] ' + queries[i] + ' [SEP]')]\n",
    "    \n",
    "    #create labels to be used for tagging from the text\n",
    "    for split_index, sent in enumerate(texts):\n",
    "        l = []\n",
    "        for word_index,word in enumerate(sent.split()):\n",
    "            if '[SEP]' in word:\n",
    "                l += ['[SEP]']\n",
    "                break\n",
    "            if '[CLS]' in word:\n",
    "                l += ['[CLS]']\n",
    "                continue\n",
    "            if not paragraph_tag:\n",
    "                print(sent,'\\n')\n",
    "                print(word)\n",
    "                print(split_index)\n",
    "            lab = paragraph_tag.pop(0)\n",
    "            word_list = tokenizer.tokenize(word)\n",
    "            for w in word_list:\n",
    "                l += [lab]\n",
    "        query_tags = copy.deepcopy(q_tags[i])\n",
    "        for word in queries[i].split():\n",
    "            lab = query_tags.pop(0)\n",
    "            word_list = tokenizer.tokenize(word)\n",
    "            for w in word_list:\n",
    "                l += [lab]\n",
    "        l += ['[SEP]']\n",
    "        labels += [l]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1585290765776,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "xP7Xi3Oem15x",
    "outputId": "20d35a5c-ef20-484b-e62e-1e7b3cc3f8d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1585290766956,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "FmQeYrAvm150",
    "outputId": "21e9a18d-cc9c-4bbb-a3c9-dc2928c107f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1585290767985,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "4OjyeT4Pm156",
    "outputId": "b153e1e4-3467-4dab-b349-b40cb03a0f8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(t) for t in tokenized_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 984,
     "status": "ok",
     "timestamp": 1585290771431,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "qnFMZW2bm16C",
    "outputId": "c0ae5d0c-cf7b-4677-efe2-ca4164f66fdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(t) for t in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1585290772721,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "yHuT5XX8m16F",
    "outputId": "4710f492-5249-4d2c-9b0f-c76eef9b64ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'isolated', 'cr', '##anial', 'distortion', 'mimic', '##king', 'cap', '##ut', 'su', '##cc', '##ede', '##num', 'from', 'am', '##nio', '##tic', 'band', 'disruption', 'without', 'any', 'neurological', 'abnormal', '##ity', 'summary', 'this', 'report', 'describes', 'a', 'term', 'newborn', 'with', 'isolated', 'distortion', 'in', 'the', 'left', 'par', '##ie', '##tal', 'bone', 'without', 'any', 'other', 'visible', 'congenital', 'anomaly', ',', 'due', 'to', 'am', '##nio', '##tic', 'band', 'disruption', '.', 'a', 'skull', 'x', '-', 'ray', ',', 'ultrasound', 'scan', 'and', 'subsequent', 'mri', 'scan', 'of', 'the', 'brain', 'did', 'not', 'show', 'any', 'apparent', 'distortion', 'apart', 'from', 'depression', 'and', 'con', '##ca', '##vity', 'in', 'the', 'left', 'par', '##ie', '##tal', 'bone', '.', 'the', 'purpose', 'of', 'this', 'case', 'report', 'is', 'to', 'raise', 'awareness', 'of', 'this', 'possible', ',', 'mild', 'outcome', 'of', 'this', 'little', '-', 'known', 'entity', ',', 'which', 'may', 'mimic', 'cap', '##ut', 'su', '##cc', '##eda', '##ne', '##um', '(', 'mo', '##uld', '##ing', 'of', 'the', 'presenting', 'part', 'in', 'the', 'birth', 'canal', 'during', 'natural', 'delivery', ')', ',', 'and', 'to', 'provide', 'a', 'historical', 'and', 'embryo', '##logical', 'background', '.', 'background', 'am', '##nio', '##tic', 'band', 'disruption', 'syndrome', 'is', 'a', 'rare', 'entity', 'which', 'occurs', 'in', '1', 'in', '1200', 'to', '1', 'in', '15', '000', 'live', 'births', '.', '1', 'it', 'may', 'cause', 'a', 'myriad', 'of', 'def', '##or', '##mit', '##ies', 'of', 'fetal', 'body', 'parts', 'from', 'mild', 'defects', 'in', 'limbs', 'to', 'severe', 'cr', '##ani', '##of', '##ac', '##ial', 'defects', 'incompatible', 'with', 'life', '.', 'the', 'spectrum', 'of', 'defects', 'includes', 'disruption', ',', 'deformation', 'and', 'mal', '##form', '##ation', 'of', 'different', 'body', 'parts', 'due', 'to', 'interference', 'from', 'the', 'am', '##nio', '##tic', 'bands', 'at', 'different', 'stages', 'of', 'organ', '##ogen', '##esis', '.', '2', '[SEP]', '[UNK]', 'isolated', 'cal', '##var', '##ial', 'def', '##or', '##mity', 'mimic', '##king', 'cap', '##ut', 'su', '##cc', '##ede', '##num', 'from', 'b', 'is', 'a', 'possibility', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 984,
     "status": "ok",
     "timestamp": 1585290775506,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "FECy2arKm16N",
    "outputId": "1fa72e4a-90c3-4126-94cf-ab202803febb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ans', 'B-ans', 'B-ans', 'I-ans', 'I-ans', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ans', 'B-ans', 'B-ans', 'I-ans', 'I-ans', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ans', 'B-ans', 'B-ans', 'I-ans', 'I-ans', 'I-ans', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '[SEP]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_6M0wWobm16Q"
   },
   "outputs": [],
   "source": [
    "DATASET_SIZE = 53914\n",
    "MAX_LEN = 424\n",
    "SEED = 520\n",
    "bs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1107,
     "status": "ok",
     "timestamp": 1585290783179,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "xqIUXyTlm16T",
    "outputId": "0ac86f55-4c6e-4801-a8a5-c8f1ba781a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101,  7275, 13675, 27532, 20870, 23150,  6834,  6178,  4904,\n",
       "       10514,  9468, 14728, 19172,  2013,  2572, 27678,  4588,  2316,\n",
       "       20461,  2302,  2151, 23130, 19470,  3012, 12654,  2023,  3189,\n",
       "        5577,  1037,  2744, 20662,  2007,  7275, 20870,  1999,  1996,\n",
       "        2187, 11968,  2666,  9080,  5923,  2302,  2151,  2060,  5710,\n",
       "       27480, 28685,  1010,  2349,  2000,  2572, 27678,  4588,  2316,\n",
       "       20461,  1012,  1037,  7412,  1060,  1011,  4097,  1010, 27312,\n",
       "       13594,  1998,  4745, 27011, 13594,  1997,  1996,  4167,  2106,\n",
       "        2025,  2265,  2151,  6835, 20870,  4237,  2013,  6245,  1998,\n",
       "        9530,  3540, 24872,  1999,  1996,  2187, 11968,  2666,  9080,\n",
       "        5923,  1012,  1996,  3800,  1997,  2023,  2553,  3189,  2003,\n",
       "        2000,  5333,  7073,  1997,  2023,  2825,  1010, 10256,  9560,\n",
       "        1997,  2023,  2210,  1011,  2124,  9178,  1010,  2029,  2089,\n",
       "       23150,  6178,  4904, 10514,  9468, 11960,  2638,  2819,  1006,\n",
       "        9587, 21285,  2075,  1997,  1996, 10886,  2112,  1999,  1996,\n",
       "        4182,  5033,  2076,  3019,  6959,  1007,  1010,  1998,  2000,\n",
       "        3073,  1037,  3439,  1998, 28086,  9966,  4281,  1012,  4281,\n",
       "        2572, 27678,  4588,  2316, 20461,  8715,  2003,  1037,  4678,\n",
       "        9178,  2029,  5158,  1999,  1015,  1999, 14840,  2000,  1015,\n",
       "        1999,  2321,  2199,  2444, 18250,  1012,  1015,  2009,  2089,\n",
       "        3426,  1037, 25028,  1997, 13366,  2953, 22930,  3111,  1997,\n",
       "       25972,  2303,  3033,  2013, 10256, 18419,  1999, 10726,  2000,\n",
       "        5729, 13675,  7088, 11253,  6305,  4818, 18419, 25876,  2007,\n",
       "        2166,  1012,  1996,  8674,  1997, 18419,  2950, 20461,  1010,\n",
       "       29130,  1998, 15451, 14192,  3370,  1997,  2367,  2303,  3033,\n",
       "        2349,  2000, 11099,  2013,  1996,  2572, 27678,  4588,  4996,\n",
       "        2012,  2367,  5711,  1997,  5812, 23924, 19009,  1012,  1016,\n",
       "         102,   100,  7275, 10250, 10755,  4818, 13366,  2953, 16383,\n",
       "       23150,  6834,  6178,  4904, 10514,  9468, 14728, 19172,  2013,\n",
       "        1038,  2003,  1037,  6061,  1012,   102,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1585290785852,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "LLh7DAC0m16W",
    "outputId": "4a2a2a44-36ce-42d0-c9d6-68d85c5af43e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81141"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1585290787485,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "B3galc1Tm16b",
    "outputId": "be741933-7277-4cd1-a206-b795176da0c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xURSe5xHm16k"
   },
   "outputs": [],
   "source": [
    "token_type_ids = []\n",
    "for ipid in input_ids:\n",
    "    type_id = 0\n",
    "    token_type_id = []\n",
    "    for myid in ipid:\n",
    "        token_type_id.append(type_id)\n",
    "        if myid == 102: \n",
    "            if type_id%2==0:\n",
    "                type_id+= 1\n",
    "            else:\n",
    "                type_id=0\n",
    "    token_type_ids.append(token_type_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1585290790927,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "iPcoqH05m16o",
    "outputId": "ba4cb8a1-5cb7-4b9d-f13a-c844d5b0aab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(token_type_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1585290793264,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "N8WJAbnDm16s",
    "outputId": "e7d0cc7d-b6c0-42bf-c6f0-48c0848e12b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_type_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1Psbm3Pm16u"
   },
   "outputs": [],
   "source": [
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"[PAD]\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1585290800600,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "X6VXMEKEm16z",
    "outputId": "c9fc58ec-8d32-4f79-875e-43297a8f208f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 897,
     "status": "ok",
     "timestamp": 1585290803462,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "whpltcgYm162",
    "outputId": "938ce556-2b00-4b45-dde7-cbabb32daa4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81141"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1585290805817,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "pmTi9xUlm168",
    "outputId": "9d124708-0632-491c-8fd9-2249ebff1e21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1971,
     "status": "ok",
     "timestamp": 1585290808393,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "C-_XjrOxm17B",
    "outputId": "5b9184a2-096a-4392-a78d-8d398d25079c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n",
    "print(attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdK7aeuNm17D"
   },
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
    "                                                            random_state=SEED, test_size=0.375)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=SEED, test_size=0.375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "586TVHQfm17F"
   },
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tzUPKESm17J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NikvdHGBm17Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIPuS7ERm17S"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeuiX7QPm17W"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2768,
     "status": "ok",
     "timestamp": 1585290822435,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "ip0X1tT_m17g",
    "outputId": "9d45acc3-5e0a-4f50-850f-312968c1b4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 10 00:04:58 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    58W / 300W |   1520MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     23062      C   /packages/7x/anaconda3/5.3.0/bin/python     1509MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24732,
     "status": "ok",
     "timestamp": 1585290847363,
     "user": {
      "displayName": "Jae Choi",
      "photoUrl": "",
      "userId": "12753612472423284421"
     },
     "user_tz": 420
    },
    "id": "uvUKzFJCm17n",
    "outputId": "20156062-ce30-4f4d-b5bb-9a4d5c480632"
   },
   "outputs": [],
   "source": [
    "#model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))\n",
    "output_dir = \"./models/\"\n",
    "# Step 2: Re-load the saved model and vocabulary\n",
    "\n",
    "# Example for a Bert model\n",
    "model = BertForTokenClassification.from_pretrained(output_dir,num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehN836-Qm17u"
   },
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kKtdGN6Cm17x",
    "outputId": "151204cb-68bb-4ed6-f5d7-ccd7f267e47b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 10 00:05:02 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    58W / 300W |   1970MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     23062      C   /packages/7x/anaconda3/5.3.0/bin/python     1959MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vozzivNcm17z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3u9x1RqFm172"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cf6AL2r1m18C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nu4SG_6ym18G"
   },
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TllKViELm18I"
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aG3KTg9Am18P",
    "outputId": "b3e59b71-830f-4265-8fd8-abb711858c22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.009138448689122279\n",
      "Validation loss: 0.0439299562061279\n",
      "Validation Accuracy: 0.6441920309803002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [37:44<5:39:44, 2264.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "    [CLS]       0.98      1.00      0.99     30428\n",
      "    [PAD]       0.00      0.00      0.00     30428\n",
      "    [SEP]       1.00      1.00      1.00     60856\n",
      "      ans       0.55      0.58      0.56     52541\n",
      "\n",
      "micro avg       0.82      0.70      0.76    174253\n",
      "macro avg       0.68      0.70      0.69    174253\n",
      "\n",
      "F1-Score: 0.7557589966878793\n",
      "Still training\n",
      "Train loss: 0.007827663870295785\n",
      "Validation loss: 0.04600662067258333\n",
      "Validation Accuracy: 0.6442355603419768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 2/10 [1:15:22<5:01:42, 2262.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "    [CLS]       1.00      1.00      1.00     30428\n",
      "    [PAD]       0.00      0.00      0.00     30428\n",
      "    [SEP]       1.00      1.00      1.00     60856\n",
      "      ans       0.58      0.52      0.55     52541\n",
      "\n",
      "micro avg       0.86      0.68      0.76    174253\n",
      "macro avg       0.70      0.68      0.69    174253\n",
      "\n",
      "F1-Score: 0.7575543274784562\n",
      "Still training\n",
      "Train loss: 0.013847463935916973\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "max_grad_norm = 1.0\n",
    "F_scores = np.zeros(epochs,float)\n",
    "patience = 6\n",
    "for e in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
    "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    c_f1 = f1_score(valid_tags, pred_tags)\n",
    "    rep = classification_report(valid_tags, pred_tags)\n",
    "    print(rep)\n",
    "    print(\"F1-Score: {}\".format(c_f1))\n",
    "    #k epochs no improvement\n",
    "    F_scores[e] = c_f1\n",
    "    prev_Fs = np.arange(e-patience,e)\n",
    "    prev_indices = prev_Fs[prev_Fs>=0]\n",
    "    if all(F_scores[e] - F_scores[prev_indices] < 0 ) and e > patience:\n",
    "        print('Done training')\n",
    "        break\n",
    "    else:\n",
    "        print('Still training')\n",
    "        #save checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHPwg8z2m18U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "md3ZYRMVm18W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSZSRGJDm18Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0566620423312722\n",
      "Validation Accuracy: 0.6440236485592783\n",
      "Validation F1-Score: 0.7495227070239342\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "    [CLS]       0.98      1.00      0.99     30428\n",
      "    [SEP]       1.00      1.00      1.00     60856\n",
      "    [PAD]       0.00      0.00      0.00     30428\n",
      "      ans       0.51      0.62      0.56     52541\n",
      "\n",
      "micro avg       0.79      0.71      0.75    174253\n",
      "macro avg       0.67      0.71      0.69    174253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "for batch in valid_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                              attention_mask=b_input_mask, labels=b_labels)\n",
    "        logits = model(b_input_ids, token_type_ids=None,\n",
    "                       attention_mask=b_input_mask)\n",
    "        \n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    true_labels.append(label_ids)\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    eval_loss += tmp_eval_loss.mean().item()\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "    nb_eval_examples += b_input_ids.size(0)\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "pred_tags = [[tags_vals[p_i] for p_i in p] for p in predictions]\n",
    "valid_tags = [[tags_vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\n",
    "print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n",
    "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Validation F1-Score: {}\".format(f1_score(valid_tags, pred_tags)))\n",
    "rep = classification_report(valid_tags, pred_tags)\n",
    "print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SxOsodim18g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models2/vocab.txt'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import WEIGHTS_NAME, CONFIG_NAME\n",
    "\n",
    "output_dir = \"./models2/\"\n",
    "\n",
    "# Step 1: Save a model, configuration and vocabulary that you have fine-tuned\n",
    "\n",
    "# If we have a distributed model, save only the encapsulated model\n",
    "# (it was wrapped in PyTorch DistributedDataParallel or DataParallel)\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBJyqrJbm18j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_NER_agave.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
