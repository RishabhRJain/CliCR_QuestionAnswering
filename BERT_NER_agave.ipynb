{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"BERT_NER_agave.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hq0DEREam14i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":972},"outputId":"1cc6ed48-737c-4ec7-8c62-39b2b1c8684a","executionInfo":{"status":"ok","timestamp":1585290291230,"user_tz":420,"elapsed":10434,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["## ---------------------- START if you want to use google colab, ---------------------- ##\n","# !pip install pytorch_transformers\n","# !pip install pytorch_pretrained_bert"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorch_transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\r\u001b[K     |█▉                              | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 10.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 8.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.38.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.18.2)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 54.2MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 52.6MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.12.27)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.21.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (0.14.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.9.5)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (1.15.27)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.3.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2019.11.28)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_transformers) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=b00cbebd0f5c63e94ed7fb22e5af15a6d113fb29e1b394ebfbb4538d45b57a87\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, pytorch-transformers\n","Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.38 sentencepiece-0.1.85\n","Collecting pytorch_pretrained_bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 9.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.38.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.12.27)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.4.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.15.27)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.5)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_pretrained_bert) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_pretrained_bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.27->boto3->pytorch_pretrained_bert) (1.12.0)\n","Installing collected packages: pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G9Xuqo_Lnb6x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"acfd4abe-2a76-4380-eb8b-a9a1295537bf","executionInfo":{"status":"ok","timestamp":1585290319181,"user_tz":420,"elapsed":31055,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["# from google.colab import drive\n","# drive.mount(\"/content/drive/\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RIeUQGWSnoK8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f6f23673-a8da-4955-f3be-550960504492","executionInfo":{"status":"ok","timestamp":1585290328113,"user_tz":420,"elapsed":3882,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["# cd drive/My\\ Drive/'YOUR DATA_PATH'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Machine_Learning/CSE576/PJ/clicr/dataset-code\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j66Agyk6noUT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c1e5bb63-74af-4772-c0a7-57d9b1526e33","executionInfo":{"status":"ok","timestamp":1585290331673,"user_tz":420,"elapsed":3255,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["# !pwd"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Machine_Learning/CSE576/PJ/clicr/dataset-code\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t-xxrjrCt8Nl","colab_type":"code","colab":{}},"source":["## ---------------------- END if you want to use google colab, ---------------------- ##"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_JyRck8UnFjj","colab_type":"code","colab":{}},"source":["import os\n","import json\n","import pandas as pd\n","import numpy as np\n","from pytorch_transformers import BertModel,BertTokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch\n","from tqdm import tqdm, trange\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoaXi2Xem14t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"outputId":"1ec1615f-9503-4889-98ca-b8f2fc3fbbd2","executionInfo":{"status":"ok","timestamp":1585290652633,"user_tz":420,"elapsed":2733,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["!nvidia-smi"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Fri Mar 27 06:30:50 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QsugR204m14y","colab_type":"code","colab":{}},"source":["from my_process_json import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1MYX5Jqm143","colab_type":"code","colab":{}},"source":["data_reader = MyDataReader('YOUR_DATA_PATH'+ 'train1.0.json',bs=500)\n","#data_reader = MyDataReader(bs=500)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qMkEAuFpm146","colab_type":"code","colab":{}},"source":["mydata = data_reader.send_batches()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lNVwj9fAm149","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"34d4f3e5-681a-492e-96e7-3ed15a001fc0","executionInfo":{"status":"ok","timestamp":1585290668951,"user_tz":420,"elapsed":690,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["dataset_size = data_reader.get_data_size()\n","dataset_size"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["500"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"CPY_5TmIm15B","colab_type":"code","colab":{}},"source":["paragraphs = [e['p'] for e in mydata].copy()\n","paragraph_tags = [e['p_tags'] for e in mydata].copy()\n","queries = [e['q'] for e in mydata].copy()\n","query_tags = [e['q_tags'] for e in mydata].copy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hZz_-jJ7m15G","colab_type":"code","colab":{}},"source":["#creating embeddings for a batch sample from CLICR\n","tags_vals = ['B-ans','I-ans','O']\n","tag2idx = {t: i for i, t in enumerate(tags_vals)}\n","tag2idx['[PAD]'] = -100\n","tags_vals+= ['[PAD]']\n","tag2idx['[SEP]'] = -100\n","tags_vals+= ['[SEP]']\n","tag2idx['[CLS]'] = -100\n","tags_vals+= ['[CLS]']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l3OInENUm15K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f5b66e0e-3a06-4350-e281-6ac653f4a53c","executionInfo":{"status":"ok","timestamp":1585290675600,"user_tz":420,"elapsed":1104,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["import torch\n","from torch.optim import Adam\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig\n","from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QyNtpN9Tm15O","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aovUCJbvm15R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"10e75e8d-733e-43ee-f089-86b186679768","executionInfo":{"status":"ok","timestamp":1585290678529,"user_tz":420,"elapsed":1014,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["device"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"UuwY9omJm15Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3f275fde-a82c-4a42-938d-bbf0728206e8","executionInfo":{"status":"ok","timestamp":1585290680272,"user_tz":420,"elapsed":996,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["torch.cuda.get_device_name(0) "],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"XFM3zvkLm15c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"271d58db-a3d5-4d9b-bf8c-1352f18d06dd","executionInfo":{"status":"ok","timestamp":1585290682959,"user_tz":420,"elapsed":1970,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 904523.41B/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BtnHuj5cm15f","colab_type":"code","colab":{}},"source":["#print(len(p_tags[1]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OiKcSTF7m15i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c9e430d3-85ca-4a14-fd94-c77a6607a383","executionInfo":{"status":"ok","timestamp":1585290704247,"user_tz":420,"elapsed":880,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["len(paragraphs[1].split())"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1025"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"OXZUfJtSm15q","colab_type":"code","colab":{}},"source":["import copy\n","split_size = 200\n","p_tags = copy.deepcopy(paragraph_tags)\n","q_tags = copy.deepcopy(query_tags)\n","tokenized_texts = []\n","labels = []\n","for i,paragraph in enumerate(paragraphs):\n","    texts = []\n","    paragraph_tag = copy.deepcopy(p_tags[i])\n","    #number of splits for current paragraph\n","    n_splits = int(len(paragraph.split())/split_size)\n","    #tokenize split paragraph text appended by full query at the end with <sep> token between paragraph and query\n","    queries[i] = queries[i].replace(\"@placeholder\",\"B\")\n","    texts += [s for s in ['[CLS] ' + ' '.join(paragraph.split()[(split_size*split):(split_size*(split+1))]) + ' [SEP] ' + queries[i] + ' [SEP]' for split in range(n_splits)]]\n","    tokenized_texts += [tokenizer.tokenize(s) for s in ['[CLS] ' + ' '.join(paragraph.split()[(split_size*split):(split_size*(split+1))]) + ' [SEP] ' + queries[i] + ' [SEP]' for split in range(n_splits)]]\n","    #tokenize remainder of splits\n","    if int(len(paragraph.split()) % split_size) > 0:\n","        texts += ['[CLS] ' + ' '.join(paragraph.split()[(n_splits*split_size):]) + ' [SEP] ' + queries[i] + ' [SEP]']\n","        tokenized_texts += [tokenizer.tokenize('[CLS] ' + ' '.join(paragraph.split()[(n_splits*split_size):]) + ' [SEP] ' + queries[i] + ' [SEP]')]\n","    \n","    #create labels to be used for tagging from the text\n","    for split_index, sent in enumerate(texts):\n","        l = []\n","        for word_index,word in enumerate(sent.split()):\n","            if '[SEP]' in word:\n","                l += ['[SEP]']\n","                break\n","            if '[CLS]' in word:\n","                l += ['[CLS]']\n","                continue\n","            if not paragraph_tag:\n","                print(sent,'\\n')\n","                print(word)\n","                print(split_index)\n","            lab = paragraph_tag.pop(0)\n","            word_list = tokenizer.tokenize(word)\n","            for w in word_list:\n","                l += [lab]\n","        query_tags = copy.deepcopy(q_tags[i])\n","        for word in queries[i].split():\n","            lab = query_tags.pop(0)\n","            word_list = tokenizer.tokenize(word)\n","            for w in word_list:\n","                l += [lab]\n","        l += ['[SEP]']\n","        labels += [l]\n","            "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xP7Xi3Oem15x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"20d35a5c-ef20-484b-e62e-1e7b3cc3f8d6","executionInfo":{"status":"ok","timestamp":1585290765776,"user_tz":420,"elapsed":1009,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["len(labels[0])"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["267"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"FmQeYrAvm150","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"21e9a18d-cc9c-4bbb-a3c9-dc2928c107f9","executionInfo":{"status":"ok","timestamp":1585290766956,"user_tz":420,"elapsed":336,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["len(tokenized_texts[0])"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["267"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"4OjyeT4Pm156","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b153e1e4-3467-4dab-b349-b40cb03a0f8d","executionInfo":{"status":"ok","timestamp":1585290767985,"user_tz":420,"elapsed":297,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["max([len(t) for t in tokenized_texts])"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["395"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"qnFMZW2bm16C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c0ae5d0c-cf7b-4677-efe2-ca4164f66fdd","executionInfo":{"status":"ok","timestamp":1585290771431,"user_tz":420,"elapsed":984,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["max([len(t) for t in labels])"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["395"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"yHuT5XX8m16F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"4710f492-5249-4d2c-9b0f-c76eef9b64ee","executionInfo":{"status":"ok","timestamp":1585290772721,"user_tz":420,"elapsed":323,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["print(tokenized_texts[0])"],"execution_count":28,"outputs":[{"output_type":"stream","text":["['[CLS]', 'isolated', 'cr', '##anial', 'distortion', 'mimic', '##king', 'cap', '##ut', 'su', '##cc', '##ede', '##num', 'from', 'am', '##nio', '##tic', 'band', 'disruption', 'without', 'any', 'neurological', 'abnormal', '##ity', 'summary', 'this', 'report', 'describes', 'a', 'term', 'newborn', 'with', 'isolated', 'distortion', 'in', 'the', 'left', 'par', '##ie', '##tal', 'bone', 'without', 'any', 'other', 'visible', 'congenital', 'anomaly', ',', 'due', 'to', 'am', '##nio', '##tic', 'band', 'disruption', '.', 'a', 'skull', 'x', '-', 'ray', ',', 'ultrasound', 'scan', 'and', 'subsequent', 'mri', 'scan', 'of', 'the', 'brain', 'did', 'not', 'show', 'any', 'apparent', 'distortion', 'apart', 'from', 'depression', 'and', 'con', '##ca', '##vity', 'in', 'the', 'left', 'par', '##ie', '##tal', 'bone', '.', 'the', 'purpose', 'of', 'this', 'case', 'report', 'is', 'to', 'raise', 'awareness', 'of', 'this', 'possible', ',', 'mild', 'outcome', 'of', 'this', 'little', '-', 'known', 'entity', ',', 'which', 'may', 'mimic', 'cap', '##ut', 'su', '##cc', '##eda', '##ne', '##um', '(', 'mo', '##uld', '##ing', 'of', 'the', 'presenting', 'part', 'in', 'the', 'birth', 'canal', 'during', 'natural', 'delivery', ')', ',', 'and', 'to', 'provide', 'a', 'historical', 'and', 'embryo', '##logical', 'background', '.', 'background', 'am', '##nio', '##tic', 'band', 'disruption', 'syndrome', 'is', 'a', 'rare', 'entity', 'which', 'occurs', 'in', '1', 'in', '1200', 'to', '1', 'in', '15', '000', 'live', 'births', '.', '1', 'it', 'may', 'cause', 'a', 'myriad', 'of', 'def', '##or', '##mit', '##ies', 'of', 'fetal', 'body', 'parts', 'from', 'mild', 'defects', 'in', 'limbs', 'to', 'severe', 'cr', '##ani', '##of', '##ac', '##ial', 'defects', 'incompatible', 'with', 'life', '.', 'the', 'spectrum', 'of', 'defects', 'includes', 'disruption', ',', 'deformation', 'and', 'mal', '##form', '##ation', 'of', 'different', 'body', 'parts', 'due', 'to', 'interference', 'from', 'the', 'am', '##nio', '##tic', 'bands', 'at', 'different', 'stages', 'of', 'organ', '##ogen', '##esis', '.', '2', '[SEP]', '[UNK]', 'isolated', 'cal', '##var', '##ial', 'def', '##or', '##mity', 'mimic', '##king', 'cap', '##ut', 'su', '##cc', '##ede', '##num', 'from', 'b', 'is', 'a', 'possibility', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FECy2arKm16N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"1fa72e4a-90c3-4126-94cf-ab202803febb","executionInfo":{"status":"ok","timestamp":1585290775506,"user_tz":420,"elapsed":984,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["print(labels[0])"],"execution_count":29,"outputs":[{"output_type":"stream","text":["['[CLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ans', 'B-ans', 'B-ans', 'I-ans', 'I-ans', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ans', 'B-ans', 'B-ans', 'I-ans', 'I-ans', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ans', 'B-ans', 'B-ans', 'I-ans', 'I-ans', 'I-ans', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '[SEP]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_6M0wWobm16Q","colab_type":"code","colab":{}},"source":["DATASET_SIZE = 53914\n","MAX_LEN = 424\n","SEED = 520\n","bs = 16"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqIUXyTlm16T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":833},"outputId":"0ac86f55-4c6e-4801-a8a5-c8f1ba781a7b","executionInfo":{"status":"ok","timestamp":1585290783179,"user_tz":420,"elapsed":1107,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n","                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","input_ids[0]"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  101,  7275, 13675, 27532, 20870, 23150,  6834,  6178,  4904,\n","       10514,  9468, 14728, 19172,  2013,  2572, 27678,  4588,  2316,\n","       20461,  2302,  2151, 23130, 19470,  3012, 12654,  2023,  3189,\n","        5577,  1037,  2744, 20662,  2007,  7275, 20870,  1999,  1996,\n","        2187, 11968,  2666,  9080,  5923,  2302,  2151,  2060,  5710,\n","       27480, 28685,  1010,  2349,  2000,  2572, 27678,  4588,  2316,\n","       20461,  1012,  1037,  7412,  1060,  1011,  4097,  1010, 27312,\n","       13594,  1998,  4745, 27011, 13594,  1997,  1996,  4167,  2106,\n","        2025,  2265,  2151,  6835, 20870,  4237,  2013,  6245,  1998,\n","        9530,  3540, 24872,  1999,  1996,  2187, 11968,  2666,  9080,\n","        5923,  1012,  1996,  3800,  1997,  2023,  2553,  3189,  2003,\n","        2000,  5333,  7073,  1997,  2023,  2825,  1010, 10256,  9560,\n","        1997,  2023,  2210,  1011,  2124,  9178,  1010,  2029,  2089,\n","       23150,  6178,  4904, 10514,  9468, 11960,  2638,  2819,  1006,\n","        9587, 21285,  2075,  1997,  1996, 10886,  2112,  1999,  1996,\n","        4182,  5033,  2076,  3019,  6959,  1007,  1010,  1998,  2000,\n","        3073,  1037,  3439,  1998, 28086,  9966,  4281,  1012,  4281,\n","        2572, 27678,  4588,  2316, 20461,  8715,  2003,  1037,  4678,\n","        9178,  2029,  5158,  1999,  1015,  1999, 14840,  2000,  1015,\n","        1999,  2321,  2199,  2444, 18250,  1012,  1015,  2009,  2089,\n","        3426,  1037, 25028,  1997, 13366,  2953, 22930,  3111,  1997,\n","       25972,  2303,  3033,  2013, 10256, 18419,  1999, 10726,  2000,\n","        5729, 13675,  7088, 11253,  6305,  4818, 18419, 25876,  2007,\n","        2166,  1012,  1996,  8674,  1997, 18419,  2950, 20461,  1010,\n","       29130,  1998, 15451, 14192,  3370,  1997,  2367,  2303,  3033,\n","        2349,  2000, 11099,  2013,  1996,  2572, 27678,  4588,  4996,\n","        2012,  2367,  5711,  1997,  5812, 23924, 19009,  1012,  1016,\n","         102,   100,  7275, 10250, 10755,  4818, 13366,  2953, 16383,\n","       23150,  6834,  6178,  4904, 10514,  9468, 14728, 19172,  2013,\n","        1038,  2003,  1037,  6061,  1012,   102,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"LLh7DAC0m16W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4a2a2a44-36ce-42d0-c9d6-68d85c5af43e","executionInfo":{"status":"ok","timestamp":1585290785852,"user_tz":420,"elapsed":921,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["len(input_ids)"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3771"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"B3galc1Tm16b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"be741933-7277-4cd1-a206-b795176da0c1","executionInfo":{"status":"ok","timestamp":1585290787485,"user_tz":420,"elapsed":921,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["len(input_ids[0])"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["424"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"xURSe5xHm16k","colab_type":"code","colab":{}},"source":["token_type_ids = []\n","for ipid in input_ids:\n","    type_id = 0\n","    token_type_id = []\n","    for myid in ipid:\n","        token_type_id.append(type_id)\n","        if myid == 102:\n","            type_id+= 1\n","    token_type_ids.append(token_type_id)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPcoqH05m16o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"ba4cb8a1-5cb7-4b9d-f13a-c844d5b0aab1","executionInfo":{"status":"ok","timestamp":1585290790927,"user_tz":420,"elapsed":280,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["print(token_type_ids[0])"],"execution_count":35,"outputs":[{"output_type":"stream","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N8WJAbnDm16s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e7d0cc7d-b6c0-42bf-c6f0-48c0848e12b1","executionInfo":{"status":"ok","timestamp":1585290793264,"user_tz":420,"elapsed":1045,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["len(token_type_ids[0])"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["424"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"q1Psbm3Pm16u","colab_type":"code","colab":{}},"source":["tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n","                     maxlen=MAX_LEN, value=tag2idx[\"[PAD]\"], padding=\"post\",\n","                     dtype=\"long\", truncating=\"post\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6VXMEKEm16z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":680},"outputId":"c9fc58ec-8d32-4f79-875e-43297a8f208f","executionInfo":{"status":"ok","timestamp":1585290800600,"user_tz":420,"elapsed":938,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["tags[0]"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-100,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    0,    0,    0,    1,    1,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    0,    0,    0,    1,    1,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    0,\n","          0,    0,    1,    1,    1,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2, -100,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n","          2,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","       -100, -100, -100, -100, -100, -100])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"whpltcgYm162","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"938ce556-2b00-4b45-dde7-cbabb32daa4a","executionInfo":{"status":"ok","timestamp":1585290803462,"user_tz":420,"elapsed":897,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["len(tags)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3771"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"pmTi9xUlm168","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9d124708-0632-491c-8fd9-2249ebff1e21","executionInfo":{"status":"ok","timestamp":1585290805817,"user_tz":420,"elapsed":931,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["len(tags[0])"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["424"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"C-_XjrOxm17B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"5b9184a2-096a-4392-a78d-8d398d25079c","executionInfo":{"status":"ok","timestamp":1585290808393,"user_tz":420,"elapsed":1971,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n","print(attention_masks[0])"],"execution_count":41,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bdK7aeuNm17D","colab_type":"code","colab":{}},"source":["tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n","                                                            random_state=SEED, test_size=0.375)\n","tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                             random_state=SEED, test_size=0.375)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"586TVHQfm17F","colab_type":"code","colab":{}},"source":["tr_inputs = torch.tensor(tr_inputs)\n","tr_tags = torch.tensor(tr_tags)\n","tr_masks = torch.tensor(tr_masks)\n","val_inputs = torch.tensor(val_inputs)\n","val_tags = torch.tensor(val_tags)\n","val_masks = torch.tensor(val_masks)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tzUPKESm17J","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NikvdHGBm17Q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIPuS7ERm17S","colab_type":"code","colab":{}},"source":["torch.cuda.empty_cache() "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AeuiX7QPm17W","colab_type":"code","colab":{}},"source":["train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n","valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n","valid_sampler = SequentialSampler(valid_data)\n","valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ip0X1tT_m17g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"outputId":"9d45acc3-5e0a-4f50-850f-312968c1b4e5","executionInfo":{"status":"ok","timestamp":1585290822435,"user_tz":420,"elapsed":2768,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["!nvidia-smi"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Fri Mar 27 06:33:40 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    25W / 250W |     10MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uvUKzFJCm17n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"20156062-ce30-4f4d-b5bb-9a4d5c480632","executionInfo":{"status":"ok","timestamp":1585290847363,"user_tz":420,"elapsed":24732,"user":{"displayName":"Jae Choi","photoUrl":"","userId":"12753612472423284421"}}},"source":["model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))\n"],"execution_count":47,"outputs":[{"output_type":"stream","text":["100%|██████████| 407873900/407873900 [00:16<00:00, 25459151.80B/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ehN836-Qm17u","colab_type":"code","colab":{}},"source":["model.cuda();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKtdGN6Cm17x","colab_type":"code","colab":{},"outputId":"151204cb-68bb-4ed6-f5d7-ccd7f267e47b"},"source":["!nvidia-smi"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Wed Mar 25 07:52:53 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:18:00.0 Off |                    0 |\n","| N/A   32C    P0    56W / 300W |   1472MiB / 16160MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|    0      6388      C   /packages/7x/anaconda3/5.3.0/bin/python     1461MiB |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vozzivNcm17z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3u9x1RqFm172","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cf6AL2r1m18C","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nu4SG_6ym18G","colab_type":"code","colab":{}},"source":["FULL_FINETUNING = True\n","if FULL_FINETUNING:\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'gamma', 'beta']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.0}\n","    ]\n","else:\n","    param_optimizer = list(model.classifier.named_parameters()) \n","    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n","optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TllKViELm18I","colab_type":"code","colab":{}},"source":["from seqeval.metrics import f1_score\n","\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aG3KTg9Am18P","colab_type":"code","colab":{},"outputId":"b3e59b71-830f-4265-8fd8-abb711858c22"},"source":["epochs = 12\n","max_grad_norm = 1.0\n","F_scores = np.zeros(epochs,float)\n","patience = 6\n","for e in trange(epochs, desc=\"Epoch\"):\n","    # TRAIN loop\n","    model.train()\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    for step, batch in enumerate(train_dataloader):\n","        # add batch to gpu\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # forward pass\n","        loss = model(b_input_ids, token_type_ids=None,\n","                     attention_mask=b_input_mask, labels=b_labels)\n","        # backward pass\n","        loss.backward()\n","        # track train loss\n","        tr_loss += loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n","        # update parameters\n","        optimizer.step()\n","        model.zero_grad()\n","    # print train loss per epoch\n","    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","    # VALIDATION on validation set\n","    model.eval()\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","    predictions , true_labels = [], []\n","    for batch in valid_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        with torch.no_grad():\n","            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n","                                  attention_mask=b_input_mask, labels=b_labels)\n","            logits = model(b_input_ids, token_type_ids=None,\n","                           attention_mask=b_input_mask)\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","        true_labels.append(label_ids)\n","        \n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        eval_loss += tmp_eval_loss.mean().item()\n","        eval_accuracy += tmp_eval_accuracy\n","        \n","        nb_eval_examples += b_input_ids.size(0)\n","        nb_eval_steps += 1\n","    eval_loss = eval_loss/nb_eval_steps\n","    print(\"Validation loss: {}\".format(eval_loss))\n","    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n","    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n","    c_f1 = f1_score(pred_tags, valid_tags)\n","    print(\"F1-Score: {}\".format(c_f1))\n","    #k epochs no improvement\n","    F_scores[e] = c_f1\n","    prev_Fs = np.arange(e-patience,e)\n","    prev_indices = prev_Fs[prev_Fs>=0]\n","    if all(F_scores[e] - F_scores[prev_indices] < 0 ) and e > patience:\n","        print('Done training')\n","        break\n","    else:\n","        print('Still training')\n","        #save checkpoint\n","        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch:   0%|          | 0/12 [00:00<?, ?it/s]WARNING: Logging before flag parsing goes to stderr.\n","E0325 08:17:09.603682 47617041186496 ultratb.py:147] Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-45-84f69950ef30>\", line 18, in <module>\n","    loss.backward()\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/site-packages/torch/tensor.py\", line 118, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 93, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/inspect.py\", line 739, in getmodule\n","    f = getabsfile(module)\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/inspect.py\", line 708, in getabsfile\n","    _filename = getsourcefile(object) or getfile(object)\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/inspect.py\", line 693, in getsourcefile\n","    if os.path.exists(filename):\n","  File \"/packages/7x/anaconda3/5.3.0/lib/python3.7/genericpath.py\", line 19, in exists\n","    os.stat(path)\n","KeyboardInterrupt\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}]},{"cell_type":"code","metadata":{"id":"oHPwg8z2m18U","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"md3ZYRMVm18W","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSZSRGJDm18Y","colab_type":"code","colab":{}},"source":["model.eval()\n","predictions = []\n","true_labels = []\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","for batch in valid_dataloader:\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    with torch.no_grad():\n","        tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n","                              attention_mask=b_input_mask, labels=b_labels)\n","        logits = model(b_input_ids, token_type_ids=None,\n","                       attention_mask=b_input_mask)\n","        \n","    logits = logits.detach().cpu().numpy()\n","    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","    label_ids = b_labels.to('cpu').numpy()\n","    true_labels.append(label_ids)\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","\n","    eval_loss += tmp_eval_loss.mean().item()\n","    eval_accuracy += tmp_eval_accuracy\n","\n","    nb_eval_examples += b_input_ids.size(0)\n","    nb_eval_steps += 1\n","\n","pred_tags = [[tags_vals[p_i] for p_i in p] for p in predictions]\n","valid_tags = [[tags_vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\n","print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n","print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SxOsodim18g","colab_type":"code","colab":{}},"source":["from pytorch_pretrained_bert import WEIGHTS_NAME, CONFIG_NAME\n","\n","output_dir = \"./models/\"\n","\n","# Step 1: Save a model, configuration and vocabulary that you have fine-tuned\n","\n","# If we have a distributed model, save only the encapsulated model\n","# (it was wrapped in PyTorch DistributedDataParallel or DataParallel)\n","model_to_save = model.module if hasattr(model, 'module') else model\n","\n","# If we save using the predefined names, we can load using `from_pretrained`\n","output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n","output_config_file = os.path.join(output_dir, CONFIG_NAME)\n","\n","torch.save(model_to_save.state_dict(), output_model_file)\n","model_to_save.config.to_json_file(output_config_file)\n","tokenizer.save_vocabulary(output_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gBJyqrJbm18j","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}